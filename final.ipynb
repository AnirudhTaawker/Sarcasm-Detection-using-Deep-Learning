{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\aadit\\OneDrive\\Desktop\\College Stuff\\C\\python\\TDL\\cuda\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from transformers import BertTokenizer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense,Dropout, SimpleRNN,LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from CSV\n",
    "data = pd.read_json(\"Sarcasm_Headlines_Dataset.json\",lines=True)\n",
    "\n",
    "# Split data into sentences and labels\n",
    "sentences = data[\"headline\"].values\n",
    "labels = data[\"is_sarcastic\"].values\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Headlines:\n",
      "1. former versace store clerk sues over secret 'black code' for minority shoppers\n",
      "\n",
      "2. the 'roseanne' revival catches up to our thorny political mood, for better and worse\n",
      "\n",
      "3. mom starting to fear son's web series closest thing she will have to grandchild\n",
      "\n",
      "4. boehner just wants wife to listen, not come up with alternative debt-reduction ideas\n",
      "\n",
      "5. j.k. rowling wishes snape happy birthday in the most magical way\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Generate word cloud\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n\u001b[0;32m     20\u001b[0m all_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sentences)\n\u001b[0;32m     21\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m WordCloud(width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m, background_color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mgenerate(all_text)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display sample data points\n",
    "print(\"Sample Headlines:\")\n",
    "for i in range(5):\n",
    "    print(f\"{i+1}. {sentences[i]}\")\n",
    "    print()\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(['Sarcastic', 'Not Sarcastic'], [sum(labels), len(labels) - sum(labels)], color=['orange', 'blue'])\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Generate word cloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "all_text = ' '.join(sentences)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
    "\n",
    "# Plot the word cloud\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Headlines')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254\n"
     ]
    }
   ],
   "source": [
    "max_sentence_length = max(len(sentence) for sentence in sentences)\n",
    "print(max_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def get_bert_embeddings(sentences, max_length=256, batch_size=8):\n",
    "    \n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    all_embeddings = []\n",
    "\n",
    "    for i in range(0, len(sentences), batch_size):\n",
    "        batch = sentences[i:i+batch_size]\n",
    "        tokenized_batch = tokenizer(batch, padding=True, truncation=True, max_length=max_length, return_tensors='pt')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**tokenized_batch)\n",
    "            embeddings = outputs.last_hidden_state.numpy()\n",
    "\n",
    "        all_embeddings.append(embeddings)\n",
    "\n",
    "    # Pad arrays to the same size\n",
    "    max_len = max(embedding.shape[1] for embedding in all_embeddings)\n",
    "    padded_embeddings = [np.pad(embedding, ((0, 0), (0, max_len - embedding.shape[1]), (0, 0)), mode='constant', constant_values=0) for embedding in all_embeddings]\n",
    "\n",
    "    # Convert the list of arrays to a single numpy array\n",
    "    return np.concatenate(padded_embeddings, axis=0)\n",
    "\n",
    "# Example usage:\n",
    "train_embeddings = get_bert_embeddings(train_sentences.tolist())\n",
    "test_embeddings = get_bert_embeddings(test_sentences.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "max_sequence_length = 128\n",
    "train_padded = pad_sequences(train_sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "test_padded = pad_sequences(test_sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "\n",
    "input_length = max_sequence_length\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.8067 - loss: 0.4150 - val_accuracy: 0.8939 - val_loss: 0.2628\n",
      "Epoch 2/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 30ms/step - accuracy: 0.9079 - loss: 0.2256 - val_accuracy: 0.8993 - val_loss: 0.2565\n",
      "Epoch 3/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - accuracy: 0.9420 - loss: 0.1503 - val_accuracy: 0.8991 - val_loss: 0.2718\n",
      "Epoch 4/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - accuracy: 0.9608 - loss: 0.0966 - val_accuracy: 0.9015 - val_loss: 0.2789\n",
      "Epoch 5/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - accuracy: 0.9792 - loss: 0.0583 - val_accuracy: 0.8948 - val_loss: 0.4043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17ebd7abeb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "\n",
    "def create_cnn_model(input_dim, max_len):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(128, 5, activation='relu', input_shape=(max_len, input_dim)))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Define input dimensions\n",
    "input_dim = train_embeddings.shape[2]  # Dimension of BERT embeddings\n",
    "max_len = train_embeddings.shape[1]  # Maximum sequence length\n",
    "\n",
    "# Create CNN model\n",
    "cnn_model = create_cnn_model(input_dim, max_len)\n",
    "\n",
    "# Compile CNN model\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train CNN model\n",
    "cnn_model.fit(train_embeddings, train_labels, epochs=5, validation_data=(test_embeddings, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"train_embeddings.npy\", train_embeddings)\n",
    "np.save(\"test_embeddings.npy\", test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadit\\OneDrive\\Desktop\\College Stuff\\C\\python\\TDL\\cuda\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Dropout\n",
    "\n",
    "def create_rnn_model(input_dim, max_len):\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(128, input_shape=(max_len, input_dim)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Define input dimensions\n",
    "input_dim = train_embeddings.shape[2]  # Dimension of BERT embeddings\n",
    "max_len = train_embeddings.shape[1]  # Maximum sequence length\n",
    "\n",
    "# Create RNN model\n",
    "rnn_model = create_rnn_model(input_dim, max_len)\n",
    "\n",
    "# Compile RNN model\n",
    "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train RNN model\n",
    "rnn_model.fit(train_embeddings, train_labels, epochs=5, validation_data=(test_embeddings, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 27ms/step - accuracy: 0.7648 - loss: 0.4928 - val_accuracy: 0.8182 - val_loss: 0.3957\n",
      "Epoch 2/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - accuracy: 0.8758 - loss: 0.3138 - val_accuracy: 0.8697 - val_loss: 0.3180\n",
      "Epoch 3/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.9066 - loss: 0.2418 - val_accuracy: 0.8590 - val_loss: 0.3332\n",
      "Epoch 4/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.9204 - loss: 0.2012 - val_accuracy: 0.8645 - val_loss: 0.2929\n",
      "Epoch 5/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 27ms/step - accuracy: 0.9381 - loss: 0.1600 - val_accuracy: 0.8955 - val_loss: 0.2810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16753dabf10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "def create_lstm_model(input_dim, max_len):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(max_len, input_dim)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Define input dimensions\n",
    "input_dim = train_embeddings.shape[2]  # Dimension of BERT embeddings\n",
    "max_len = train_embeddings.shape[1]  # Maximum sequence length\n",
    "\n",
    "# Create LSTM model\n",
    "lstm_model = create_lstm_model(input_dim, max_len)\n",
    "\n",
    "# Compile LSTM model\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train LSTM model\n",
    "lstm_model.fit(train_embeddings, train_labels, epochs=5, validation_data=(test_embeddings, test_labels))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aadit\\OneDrive\\Desktop\\College Stuff\\C\\python\\TDL\\cuda\\lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 193ms/step - accuracy: 0.8282 - loss: 0.3796 - val_accuracy: 0.8804 - val_loss: 0.2781\n",
      "Epoch 2/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 176ms/step - accuracy: 0.9037 - loss: 0.2317 - val_accuracy: 0.9025 - val_loss: 0.2357\n",
      "Epoch 3/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 176ms/step - accuracy: 0.9375 - loss: 0.1636 - val_accuracy: 0.9088 - val_loss: 0.2265\n",
      "Epoch 4/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 171ms/step - accuracy: 0.9556 - loss: 0.1114 - val_accuracy: 0.9111 - val_loss: 0.2390\n",
      "Epoch 5/5\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 161ms/step - accuracy: 0.9744 - loss: 0.0696 - val_accuracy: 0.9058 - val_loss: 0.2925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17e250b6e20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "\n",
    "def create_bidirectional_lstm_model(input_dim, max_len):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(128), input_shape=(max_len, input_dim)))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Define input dimensions\n",
    "input_dim = train_embeddings.shape[2]  # Dimension of BERT embeddings\n",
    "max_len = train_embeddings.shape[1]  # Maximum sequence length\n",
    "\n",
    "# Create bi-directional LSTM model\n",
    "bidirectional_lstm_model = create_bidirectional_lstm_model(input_dim, max_len)\n",
    "\n",
    "# Compile bi-directional LSTM model\n",
    "bidirectional_lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train bi-directional LSTM model\n",
    "bidirectional_lstm_model.fit(train_embeddings, train_labels, epochs=5, validation_data=(test_embeddings, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Save the weights of CNN model\n",
    "# Save the weights of CNN model\n",
    "cnn_model.save_weights(\"cnn_model_weights.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bidirectional_lstm_model.save_weights(\"bidirectional_lstm_model_weights.weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_embeddings: (21367, 66, 768)\n",
      "Shape of test_embeddings: (5342, 37, 768)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the embeddings before reshaping\n",
    "print(\"Shape of train_embeddings:\", train_embeddings.shape)\n",
    "print(\"Shape of test_embeddings:\", test_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5688880569075253\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Initialize Naive Bayes classifier\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "\n",
    "# Define the maximum sequence length\n",
    "max_len = 66  # Maximum sequence length\n",
    "\n",
    "# Pad or truncate the test embeddings to match the sequence length of train embeddings\n",
    "test_embeddings_adjusted = pad_sequences(test_embeddings, maxlen=max_len, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "# Reshape the embeddings for Naive Bayes input\n",
    "train_embeddings_reshaped = train_embeddings.reshape(train_embeddings.shape[0], -1)\n",
    "test_embeddings_reshaped = test_embeddings_adjusted.reshape(test_embeddings_adjusted.shape[0], -1)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "naive_bayes_classifier.fit(train_embeddings_reshaped, train_labels)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = naive_bayes_classifier.score(test_embeddings_reshaped, test_labels)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7701235492324972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define the maximum sequence length\n",
    "max_len = 66  # Maximum sequence length\n",
    "\n",
    "# Pad or truncate the test embeddings to match the sequence length of train embeddings\n",
    "test_embeddings_adjusted = pad_sequences(test_embeddings, maxlen=max_len, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "# Reshape the embeddings for KNN input\n",
    "train_embeddings_reshaped = train_embeddings.reshape(train_embeddings.shape[0], -1)\n",
    "test_embeddings_reshaped = test_embeddings_adjusted.reshape(test_embeddings_adjusted.shape[0], -1)\n",
    "\n",
    "# Initialize KNN classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
    "\n",
    "# Train the KNN classifier\n",
    "knn_classifier.fit(train_embeddings_reshaped, train_labels)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = knn_classifier.score(test_embeddings_reshaped, test_labels)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7787345563459378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define the maximum sequence length\n",
    "max_len = 66  # Maximum sequence length\n",
    "\n",
    "# Pad or truncate the test embeddings to match the sequence length of train embeddings\n",
    "test_embeddings_adjusted = pad_sequences(test_embeddings, maxlen=max_len, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "# Reshape the embeddings for KNN input\n",
    "train_embeddings_reshaped = train_embeddings.reshape(train_embeddings.shape[0], -1)\n",
    "test_embeddings_reshaped = test_embeddings_adjusted.reshape(test_embeddings_adjusted.shape[0], -1)\n",
    "\n",
    "# Initialize KNN classifier\n",
    "knn_classifier64 = KNeighborsClassifier(n_neighbors=40)  # You can adjust the number of neighbors as needed\n",
    "\n",
    "# Train the KNN classifier\n",
    "knn_classifier64.fit(train_embeddings_reshaped, train_labels)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = knn_classifier64.score(test_embeddings_reshaped, test_labels)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
      "SVM Accuracy: 0.9198801946836391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Combine the outputs of CNN and Bi-directional LSTM models\n",
    "combined_features_train = np.concatenate((cnn_model.predict(train_embeddings),\n",
    "                                          bidirectional_lstm_model.predict(train_embeddings)), axis=1)\n",
    "combined_features_test = np.concatenate((cnn_model.predict(test_embeddings),\n",
    "                                         bidirectional_lstm_model.predict(test_embeddings)), axis=1)\n",
    "\n",
    "# Create and train SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(combined_features_train, train_labels)\n",
    "\n",
    "# Make predictions on test data\n",
    "svm_predictions = svm_model.predict(combined_features_test)\n",
    "\n",
    "# Evaluate SVM model\n",
    "svm_accuracy = accuracy_score(test_labels, svm_predictions)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step\n",
      "\u001b[1m668/668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m167/167\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step\n",
      "SVM Accuracy: 0.9166978659678023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Get predictions from the KNN classifier on the training set\n",
    "knn_train_predictions = knn_classifier64.predict(train_embeddings_reshaped)\n",
    "\n",
    "# Combine the outputs of CNN, Bi-directional LSTM, and KNN models\n",
    "combined_features_train = np.concatenate((cnn_model.predict(train_embeddings), \n",
    "                                          bidirectional_lstm_model.predict(train_embeddings),\n",
    "                                          knn_train_predictions.reshape(-1, 1)), axis=1)\n",
    "combined_features_test = np.concatenate((cnn_model.predict(test_embeddings), \n",
    "                                         bidirectional_lstm_model.predict(test_embeddings),\n",
    "                                         knn_predictions.reshape(-1, 1)), axis=1)\n",
    "\n",
    "# Create and train SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(combined_features_train, train_labels)\n",
    "\n",
    "# Make predictions on test data\n",
    "svm_predictions = svm_model.predict(combined_features_test)\n",
    "\n",
    "# Evaluate SVM model\n",
    "svm_accuracy = accuracy_score(test_labels, svm_predictions)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the SVM model weights\n",
    "with open(\"svm_model_weights.pkl\", \"wb\") as f:\n",
    "    pickle.dump(svm_model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-sarcasm-detection",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
